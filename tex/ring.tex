%%
%% ring.tex
%% 
%% Made by Alex Nelson <pqnelson@gmail.com>
%% Login   <alex@lisp>
%% 
%% Started on  2025-07-20T10:08:56-0700
%% Last update 2025-07-20T10:08:56-0700
%% 

\chapter{Ring Theory}

\section{Rings}

\begin{definition}[Distributive double magmas]\mml{vectsp_1:def 7}\label{defn:double-magma:distributive}
Let $D=\structure{U,\cdot,+}$ be a nonempty double magma. We call $D$
\define{Distributive} if multiplication distributes over addition,
i.e.,
\begin{itemize}
\property{Left distributivity} $x(y+z)=xy+xz$ for all $x,y,z\in D$,
\property{Right distributivity} $(x+y)z=xz+yz$ for all $x,y,z\in D$.
\end{itemize}
\end{definition}

\begin{definition}[Unital Ring]\mml{vectsp_1}
A \define{Unital Ring} consists of a non empty double loop structure
$R=\structure{U,+,\cdot,0_{U},1_{U}}$ such that
\begin{itemize}
\property{Abelian} addition is commutative, i.e., for all $x,y\in R$
  we have $x + y = y + x$
\property{Addition is associative} for all $x,y,z\in R$ we have
  $(x+y)+z=x+(y+z)$
\property{Right complementable} for every $x\in R$, there exists a
  $y\in R$ such that $x + y = 0_{U}$.
\property{Right zeroed} for every $x\in R$ we have $x + 0_{U} = x$
\property{Multiplication is associative} for all $x,y,z\in R$
  we have $(x\cdot y)\cdot z=x\cdot(y\cdot z)$
\property{Well-Unital} for all $x\in R$ we have $x\cdot 1_{U}=x$ and
  $1_{U}\cdot x = x$
\property{Distributive} multiplication distributes over addition as
  per Definition~\ref{defn:double-magma:distributive}.
\end{itemize}
\end{definition}

\begin{remark}[Ring = Abelian additive group + multiplication]
We could define a ring to be an Abelian additive group equipped with a
bilinear operator which is its multiplication operator. Distributivity
of multiplication over addition comes for ``free'' from
bilinearity. This means that a ring is a monoid object in the category
of Abelian groups.
\end{remark}

\begin{remark}[Non-unital rings]
Here's where we run into issues with the ``willinilly'' attitude the
Working Mathematician adopts. A non-unital ring would be a ringoid
satisfying all the properties of a unital ring \emph{except} the
well-unital property. We should think of this as a ring, and that
we can use the ``unital'' property from Definition~\ref{defn:monoid}.
Programmers would call this reworking of things ``refactoring''.

Arguably, we could weaken things even further and remove the
requirement that a ring is associative under multiplication. This
would allow us to define, e.g., a [not-necessarily-associative]
algebra over a ring $R$ is a module over $R$ which is also a ring.
Lie Algebras are an example of this. For algebraic geometers,
associativity may be safely assumed for the rings of interest.
\end{remark}

\begin{example}[Noncommutative and commutative rings]
Consider the ring of $2\times 2$ matrices over $\RR$. This is famously
a noncommutative ring (i.e., multiplication is a noncommutative operator).
This is also a unital ring since the identity matrix is its identity
element. 

On the other hand, $\RR$ equipped with the usual multiplication and
addition operations forms a commutative ring.

Hence we can use both ``commutative'' and ``noncommutative'' as
adjectives for ``unital ring'' (and for ``ring'').
\end{example}

\begin{example}[Ring of endomorphisms]
Let $G$ be an Abelian group.
Consider the set $\End(G)$ of endomorphisms of $G$. We claim this
forms a ring.

\begin{proof}
We have $f_{1}$, $f_{2}\in\End(G)$. We define $f_{1}+f_{2}$ by
$(f_{1}+f_{2})(g)=f_{1}(g)+f_{2}(g)$ for each $g\in G$. When equipped
with this, we find $\End(G)$ forms an Abelian group with identity
element $e(g)=0$ for all $g\in G$. The operator is commutative since
$G$ is an \emph{Abelian} group.

We can define multiplication by $f_{1}f_{2} = f_{1}\circ f_{2}$. The
identity element for this multiplication is $\id_{G}$, and it is
associative. We see that this is left-distributive
$(f_{1}(f_{2}+f_{3}))(g)=f_{1}(f_{2}(g)+f_{3}(g))=f_{1}(f_{2}(g))+f_{1}(f_{3}(g))$ 
by $f_{i}$ being group morphisms. The proof for right-distributivity
is similar.
\end{proof}
\end{example}

\begin{example}[Boolean rings]
Consider the ring $B = \structure{\{0,1\}, 0_{B} = 0, 1_{B} = 1, +, \star}$
where we define addition by the rules $0+x=x+0=x$ and $1+1=0$, and we
define multiplication by the rules $1\star x=x\star 1=x$ and $0\star x=x\star0=0$.
This is the \define{Canonical Boolean Ring}.

More generally, let $X$ be a set. We can form a ring $R=\structure{\powerset{X},+=\symdiff,\star=\cap,1_{R}=X,0_{R}=\emptyset}$.
This is a Boolean ring over $X$. When $X$ is a singleton, this is
isomorphic to the canonical Boolean ring.
\end{example}

\begin{theorem}[Zero absorps stuff in a ring]\mml{vectsp_1:6}
Let $R$ be a nonempty right complementable, right zeroed, right
distributive double loop structure with associative addition.
Let $x\in R$ be any element.
Then $x\cdot 0_{R}=0_{R}$.
\end{theorem}

\begin{proof}
We see that (by right zeroed and distributivity)
\begin{equation*}
\begin{aligned}
(x\cdot 0_{R}) + 0_{R} &= (x\cdot(0_{R} + 0_{R})) + 0_{R}\\
&= x\cdot(0_{R} + 0_{R})\\
&= (x\cdot0_{R}) + (x\cdot0_{R}).\\
\end{aligned}
\end{equation*}
Hence the result by Definition of right-complementable.
\end{proof}

\begin{definition}[Zero-divisor]\mml{ringfrac:def 1}
Let $R$ be a ring, let $x\in R$ be nonzero $x\neq 0$.
We call $x$ a \define{Zero-Divisor} if there exists a $y\in R$ such
that $y\neq0$ and either $xy=0$ or $yx=0$.

If $x$ is not a zero-divisor, we call it a \emph{nonzero-divisor}.
\end{definition}

\begin{definition}[Domains and Integral Domains]\mml{vectsp_2}
A \define{Domain} is a non-degenerate ring $R$ such that
\begin{itemize}
\property{Zero-product property}\mml{vectsp_2:def 1} For any $x$, $y\in R$, if $xy=0$,
then either $x=0$ or $y=0$. (In other words, there are no zero-divisors.)
\end{itemize}
Furthermore, if $R$ is a commutative Domain, then we call it an
\define{Integral Domain}.
\end{definition}

\begin{remark}[History of integral domains]
David Hilbert's \emph{Zahlbericht} (\S31, 1897) uses the phrase ``\German{Integrit\"{a}tsbereich}''
(which is the German word for ``integral domain''), but the notion
seems to have appeared earlier in Kronecker's \emph{Grundz\"{u}ge einer arithmetischen Theorie der algebraischen Gr\"{o}ssen}
(1882) when discussing ``\German{Rationalit\"{a}ts-Bereich}'' as well
as Dedekind's Supplement XI [\emph{\"{U}ber die Theorie der ganzen algebraischen Zahlen}] to Dirichlet's \emph{Vorlesungen \"{u}ber Zahlentheorie}
(republished in volume 3 of Dedekind's collected works). Hilbert cites
both Kronecker and Dedekind for using the notion implicitly, but
Hilbert named it. Emmy Noether, to whom all Mathematicians owe a debt
we can never hope to repay, cast integral domains in the more
recognizable form in her paper ``Idealtheorie in Ringbereichen''
(\journal[Math. Ann.]{Mathematische Annalen} \volume{83} (1921) 24--66).
% https://math.stackexchange.com/a/46026/31693
\end{remark}

\begin{definition}[Almost left invertible]\mml{vectsp_1:def 9}
Let $M$ be a multiplicative loop with zero structure.
We can define the attribute calling $M$ \define{Almost Left Invertible} 
if for every $x\in M$ such that $x\neq 0_{M}$ there exists a $y\in M$
such that $yx=1_{M}$.
\end{definition}

\begin{definition}[Skew-field or division rings]\mml{vectsp_1}
We define a \define{Skew-field} (or \emph{Division Ring}) to be a
nondegenerate almost left invertible unital Ring.
\end{definition}

\begin{example}[Quaternions form a skew-field]
The canonical example of a skew-field is the quaternions $\HH$.
\end{example}

\begin{theorem}[Endomorphism ring of a simple module is a skew-field]
Let $R$ be a ring, let $M$ be a simple module over $R$. Then the endomorphism ring $\End(M)$ is a
skew-field.
\end{theorem}

This follows by Schur's lemma.

\begin{definition}[Field]\mml{vectsp_1}
We define a \define{Field} to be a commutative Skew-field.
\end{definition}

\begin{example}[Finite field of order $p$]
Let $p$ be a prime number. Consider $\FF_{p}$ consisting of natural
numbers up to $p$ equipped with addition of integers taken modulo $p$,
multiplication of integers taken modulo $p$. Then $\FF_{p}$ is a
finite field.
\end{example}

\begin{definition}[Units and Group of Units]\mml{matgrp_0}
Let $R$ be a unital ring, let $x\in R$ be an element of $R$.
We call $x$ a \define{Unit} if there exists an element $y\in R$
such that $xy=1_{R}$ and $yx=1_{R}$. Observe that $1_{R}$ is a unit.

The collection of all such units forms a group under multiplication
from $R$. We refer to this group as the \define{Group of Units} and
denote it by $\UnitGroup{R}$
\end{definition}

\begin{remark}[Number of one-sided inverses]
It is important that we have \emph{both} $xy=1_{R}$ and $yx=1_{R}$ in
the definition of units because if we just imposed one condition, say
$xy=1_{R}$, then one of the following is true: there is no such $y$,
or else there is a unique $y$, or else there are infinitely many such $y$.
When we impose the second condition (that we must also have $yx=1_{R}$),
then there is either zero or one such $y$. This result is known as
``Kaplansky's theorem''.
\end{remark}

\begin{theorem}[(Kaplansky) Non-uniqueness of right inverses in Ring]
Let $R$ be a unital ring, let $x$ be an element of $R$.
Suppose there exists a right inverse of $x$ in $R$, but there is no
left inverse of $x$ in $R$. Then there are infinitely many right
inverses of $x$ in $R$.
\end{theorem}

Dijkstra worked through this theorem in EWD1124. His proof is a little
too slick for my preferences. A particularly noteworthy proof may be
found in Bitzer~\cite{bitzer1963inverses}, which does not rely on the
ring structure.

\begin{proof}[Proof sketch]
We assume there exists a right inverse of $x$ in $R$, i.e., there is
an element $r\in R$ such that
\begin{equation}
xr = 1_{R}.
\end{equation}
Consider the sequence $c_{n}=r+(1-rx)x^{n}$ with $c_{0}=r$. We claim
that $xc_{n}=xr+x(1-rx)x^{n}=1+(x-xrx)x^{n}=1+(x-1_{R}x)x^{n}=1+0$,
hence $c_{n}$ is another right inverse of $x$.

We claim $c_{n}$ are distinct. Assume for contradiction that
$c_{n}=c_{k}$ and $n\neq k$. Then we have
\begin{equation}
(1-rx)x^{n}=(1-rx)x^{k}.
\end{equation}
Suppose $k<n$. Then we can multiply on the right by $r^{k}$ to obtain
\begin{equation}
(1-rx)x^{n}r^{k}=(1-rx)x^{k}r^{k}=(1-rx)(xr)^{k}=1-rx.
\end{equation}
This means, in particular,
\begin{equation}
(1-rx)x^{n-k}+rx = \bigl((1-rx)x^{n-k-1}+r\bigr)x=1,
\end{equation}
and therefore we have obtained a left inverse of $x$. But this is a
contradiction. Therefore we reject our assumption, and conclude that
$c_{n}\neq c_{k}$ for $n\neq k$.
\end{proof}

\subsection{Ring morphisms}

\begin{definition}[Ring morphism, endomorphism, and isomorphism]\mml{quofield, ringcat1:def 1}
Let $R_{1}$ and $R_{2}$ be rings. We define a \define{Ring Morphism}
to be a function $f\colon R_{1}\to R_{2}$ such that
\begin{itemize}
\property{Additive} for any $x$, $y\in R_{1}$, we have $f(x+y)=f(x)+f(y)$
\property{Preserves zero} we have $f(0_{R_{1}})=0_{R_{2}}$
\property{Multiplicative} for any $x$ and $y\in R_{1}$, we have $f(xy)=f(x)f(y)$.
\property{Unit-preserving} When $R_{1}$ and $R_{2}$ are unital rings,
  we have $f(1_{R_{1}})=1_{R_{2}}$
\end{itemize}%
That is to say, it is a morphism of the underlying Abelian groups such
that it is multiplicative.

When $R_{1} = R_{2}$, the ring morphism is referred to as a
\define{Ring Endomorphism}.

Furthermore, a \define{Ring Isomorphism}\mml{mod_4:def 12} is a bijective ring morphism.
A ring endomorphism which is also an isomorphism is called a
\define{Ring Automorphism}.
\end{definition}

\begin{theorem}[Ring morphisms never map one to zero]
Let $R_{1}$, $R_{2}$ be nondegenerate rings.
Let $f\colon R_{1}\to R_{2}$ be a ring morphism.
Then $f(1)\neq0$.
\end{theorem}

\begin{example}%[Identity ring automorphism]
Let $R$ be a ring. Then $\id_{R}\colon R\to R$ is a ring morphism.
\end{example}

(This is a fact registered in \texttt{ringcat1} and \texttt{ring\_2}.)

\begin{example}[Automorphism of field of complex numbers]
Complex conjugation $\gamma\colon\CC\to\CC$, $\gamma(x+\I y)=x-\I y$,
is an automorphism of $\CC$. The only \emph{continuous} functions of
complex numbers which are also field automorphisms are the identity
function and complex conjugation.

Any automorphism $\alpha$ of $\CC$ must leave the rational numbers
invariant $\alpha(q)=q$ for each $q\in\QQ$.

We refer to automorphisms of $\CC$ which are neither $\id_{\CC}$ nor
complex conjugation as \define{Wild Automorphisms} of $\CC$.
Constructing a wild automorphism explicitly requires the axiom of choice,
and are far from continuous. Kestelman~\cite{kestelman1951automorphisms}
first discussed them.
\end{example}

\begin{example}[Not every two rings have a morphism between them]
Here are a number of times where there are no ring morphisms between
two rings.
\begin{enumerate}
\item Consider two primes $p\neq q$. There is no unit-preserving ring
morphism from the finite field of $p$ elements $\FF_{p}$ to the finite
field of $q$ elements $\FF_{q}$. (Hint: suppose
$f\colon\FF_{p}\to\FF_{q}$ is a ring morphism. Then
$qf(1)=0=f(p1)=pf(1)$ which implies $f(1)=0$.)
\item  There is no unit-preserving ring morphism from the ring of 2-by-2
matrices over the integers to the integers $M_{2}(\ZZ)\to\ZZ$.
\item There is no unit-preserving ring morphism $\QQ\to\ZZ$.
\end{enumerate}
\end{example}

\begin{definition}[$R$-homomorphic rings]\mml{ring_2:def 4}
Let $S$ and $R$ be rings.
We say $S$ is \define{$R$-Homomorphic} if there exists a ring morphism
$f\colon R\to S$.
\end{definition}

\begin{example}[Existence of canonical ring morphism $\ZZ\to R$]\mml{ring_3:def 8}
Let $R$ be any unital ring. There exists a canonical ring morphism
$f\colon\ZZ\to R$ defined by $f(1_{\ZZ})=1_{R}$.
\end{example}

\earmuffed
\begin{theorem}[Uniqueness of canonical ring morphism $\ZZ\to R$]\mml{ring_3:84}
Let $R$ be any unital ring.
Let $f\colon\ZZ\to R$ be a ring morphism.
Then $f$ is equal to the canonical ring morphism from $\ZZ$ to $R$.
\end{theorem}

\begin{remark}[Unit-preserving condition arguably un-natural]
It is arguable that the condition $f(1)=1$ is too much, because unital
rings are less ``natural'' than possibly-nonunital rings. For example,
the kernel of a unital ring morphism is not a unital ring. But the
kernel of a unital ring morphism \emph{is} an Abelian subgroup.
\end{remark}

\begin{theorem}[Composing ring morphisms yields a ring morphism]\mml{ringcat1:1}
Let $R_{1}$, $R_{2}$, $R_{3}$ be non empty double loop structures.
Let $f\colon R_{1}\to R_{2}$ and $g\colon R_{2}\to R_{3}$ be additive,
multiplicative, unit-preserving functions. Then $g\circ f\colon R_{1}\to R_{3}$
is an additive, multiplicative, unit-preserving function.
\end{theorem}

\begin{definition}[Kernel of a ring morphism]\mml{vectsp10:def 9}
Let $R$ and $S$ be rings. Let $f\colon R\to S$ be a ring morphism.
We define the \define{Kernel} of $f$ to be a subset of $R$ equal to
$\ker(f):=\{x\in R\mid f(x)=0\}$.
\end{definition}

\begin{remark}
We can define the kernel more generally for any non-empty 1-sorted
structure $R$ and any zero-structure $S$. The definition we just gave
still holds (the kernel is the set of all elements mapped to zero).
\end{remark}

\begin{theorem}[Ring morphism is injective iff its kernel is zero]\mml{ring_2:12}
Let $R$ be a ring. Let $S$ be an $R$-homomorphic ring.
Let $f\colon R\to S$ be a ring morphism.
Then $f$ is injective if and only if $\ker(f)=\{0\}$.
\end{theorem}

\begin{definition}[Isomorphic rings]\mml{quofield:def 23}
Let $R$ and $S$ be nonempty double loop structures.
We define the predicate, saying $R$ and $S$ \define{are isomorphic}
if there exists a [ring] isomorphism $f\colon R\to S$.
This is obvious reflexive (since the identity is an isomorphism of rings).
\end{definition}

\begin{theorem}[``Are isomorphic rings'' is a symmetric predicate]\mml{quofield:def 23}
Let $R$ and $S$ be nonempty double loop structures.
If $R$ is isomorphic to $S$, then $S$ is isomorphic to $R$.
\end{theorem}

\begin{proof}
Let $f\colon R\to S$ be a ring isomorphism. We claim $f^{-1}\colon S\to R$
is
\begin{enumerate}
\item a ring morphism (suffices to check
  $f^{-1}(x+y)=f^{-1}(x)+f^{-1}(y)$, $f^{-1}(xy)=f^{-1}(x)f^{-1}(y)$, $f^{-1}(1)=1$), and
\item surjective, and
\item injective.
\end{enumerate}
Hence the result.
\end{proof}

\begin{theorem}[``Are isomorphic rings'' is transitive]\mml{ring_3:44}
Let $R$, $S$, $T$ be nonempty double loop structures.
If $R$ is isomorphic to $S$, and $S$ is isomorphic to $T$,
then $R$ is isomorphic to $T$.
\end{theorem}

\begin{proof}
Let $f\colon R\to S$ and $g\colon S\to T$ be the ring isomorphisms.
We see that $g\circ f\colon R\to T$ is a ring morphism. We claim it is
a ring isomorphism. We see that $g\circ f$ is both surjective and
injective (since composing surjective functions is surjective, and
composing injective functions is injective). Hence the result.
\end{proof}

\begin{remark}[``Are isomorphic rings'' forms an equivalence relation]
The previous two theorems proves that ``are isomorphic rings'' forms a
symmetric and transitive binary predicate, and we remarked when we
defined the predicate that it is reflexive. This combines together to
tell us we have an equivalence relation of rings.
\end{remark}

\subsection{Subrings}

\begin{definition}[Subrings]\mml{c0sp1:def 3}
Let $R$ be a ring. We define a \define{Subring} of $R$ to be a ring
$S$ such that $S\subset R$ and $0_{S}=0_{R}$ and the binary operators
of $S$ are the binary operators of $R$ restricted to $S$, i.e., that
$+_{S} = +_{R}|_{S\times S}$ and  $\star_{S} = \star_{R}|_{S\times S}$.

Furthermore, when $R$ is a unital ring, we call $S$ a \define{Unital Subring} 
of $R$ if we also have $1_{S}=1_{R}$ in addition to the preceding
properties. 
\end{definition}

\begin{theorem}[Subring is a transitive notion]\mml{algnum_1:1}
If $R_{1}$ is a subring of $R_{2}$, and $R_{2}$ is a subring of
$R_{3}$, then $R_{1}$ is a subring of $R_{3}$.
\end{theorem}

\begin{example}\mml{algnum_1:3,4 liouvil2:3,4,5 ring_3:47}
We see $\ZZ$ is a subring of $\QQ$, and $\QQ$ is a subring of $\RR$,
and $\RR$ is a subring of $\CC$,
and $\CC$ is a subring of $\HH$.

Consequently, we see that $\ZZ$ is a subring of $\CC$, $\QQ$ is a
subring of $\CC$, $\ZZ$ is a subring of $\RR$. These facts follow from
the transitivity of subrings.
\end{example}

\begin{theorem}\mml{field_6:13}
Let $R$ be a ring. Let $R_{1}$, $R_{2}$ be subrings of $R$.
Then $R_{1}$ is a subring of $R_{2}$ if and only if the underlying
sets satisfy $U(R_{1})\subset U(R_{2})$.
\end{theorem}

\begin{theorem}\mml{field_6:12}
Let $R_{1}$, $R_{2}$ be [strict] rings.
If $R_{1}$ is a subring of $R_{2}$ and $R_{2}$ is a subring of
$R_{1}$, then $R_{1}=R_{2}$.
\end{theorem}

\begin{definition}[Center of a ring]\mml{weddwitt:def 4}
Let $R$ be a (possibly non-unital) ring. We define the \define{Center} of $R$
to be the commutative Subring of $R$ denoted $Z(R)$ such that
for $z\in R$ we have $z\in Z(R)$ iff for all $x\in R$ we have $zx=xz$.
That is to say, $Z(R)$ consists of all elements which commute with
everything in $R$.
\end{definition}

\begin{theorem}
The center of a skew-field is a field.
\end{theorem}

(This is a registered fact in \texttt{WEDDWITT}.)

\begin{theorem}[Wedderburn's theorem]\mml{weddwitt:38}
Every finite Skew-field is commutative (i.e., a field).
\end{theorem}

\begin{definition}[Image of a ring morphism]\mml{ring_2:def 6}
Let $R$, $S$ be rings. Let $f\colon R\to S$ be a ring morphism.
Then the \define{Image} of $f$ is a [strict] Subring of $S$ denoted $\Im(f)$
whose underlying set is $\rng(f)$.
\end{definition}

\section{Formal Polynomials}

\begin{remark}[Formalization of formal polynomials]
It appears that formal polynomials were taken for granted until people
tried formalizing them in proof assistants. The earliest formalization
of formal polynomials may be found in \Mizar/. See Piotr Rudnicki
and Andrzej Trybulec's ``Multivariate Polynomials with Arbitrary
Number of Variables'' (\journal[Formaliz.\ Math.]{Formalized Mathematics}
\volume{9}
no.1 (2001) pp.95--110) which was reinvented multiple times.\nocite{rudnicki2001multivariate}

The basic idea is to work with a notion of ``bags''. A bag of a set
$X$ is a natural-valued function on $X$ which is zero almost everywhere.
When $X=\{x_{1},\dots,x_{n}\}$, a bag $b$ corresponds to the monomial
$x_{1}^{b_{1}}\cdots x_{n}^{b_{n}}$. (We abuse notation, abbreviating
$b_{x_{i}}$ to $b_{i}$.) Then a formal series is a
function from the set of bags on $X$ to the set of coefficients, and a
formal polynomial is a formal series with finite support.
\end{remark}

\begin{definition}[Multi-index]
Let $n$ be a natural number. We define an $n$-dimensional \define{Multi-Index}
to be an $n$-tuple of numbers
$\alpha=(\alpha_{1},\dots,\alpha_{n})$.

We can define, for any two $n$-dimensional multi-indices
$\alpha\in\NN_{0}^{n}$ and $\beta\in\NN_{0}^{n}$, the following
operations:
\begin{itemize}
\item Componentwise sum and difference: $\alpha\pm\beta=(\alpha_{1}\pm\beta_{1},\dots,\alpha_{n}\pm\beta_{n})$
\item Componentwise monus: $\alpha\monus\beta=(\alpha_{1}\monus\beta_{1},\dots,\alpha_{n}\monus\beta_{n})$
\item Partial order $\alpha\leq\beta$ iff $\alpha_{i}\leq\beta_{i}$
\item Sum of components: $|\alpha|=\alpha_{1}+\cdots+\alpha_{n}$
\item Factorial: $\alpha!=\alpha_{1}!\cdot\alpha_{2}!\cdots\alpha_{n}!$
\item If $R$ is a structure with multiplication, and $x\in R^{n}$ is a
  tuple $x=(x_{1},\dots,x_{n})$, then we
  could define $x^{\alpha} = x_{1}^{\alpha_{1}}x_{2}^{\alpha_{2}}(\cdots)x_{n}^{\alpha_{n}}$.
\end{itemize}
\end{definition}

\begin{remark}[Informal definition of polynomial ring]
Let us review the informa definition for the polynomial ring.
Let $R$ be a ring. We define the \emph{Ring of Polynomials} with
coefficients in $R$ and in the unknowns $X_{1},\dots,X_{n}$ to be the
ring $R[X_{1},\dots,X_{n}]$ consisting of linear combinations of
monomials $X_{1}^{m_{1}}\cdots X_{n}^{m_{n}}$ which we often just
write out using multi-index notation as
\begin{equation}
p(X_{1},\dots,X_{n}) = \sum_{|\alpha|\leq N} c_{\alpha}X^{\alpha}
\end{equation}
where $N$ is the degree of $p$,
and $c_{\alpha}=c_{\alpha_{1},\dots,\alpha_{n}}$,
and $X^{\alpha} = X_{1}^{\alpha_{1}}(\cdots)X_{n}^{\alpha_{n}}$. 
\end{remark}

\begin{definition}[Bags]\mml{pre_poly}
Let $X$ be a set.

A \define{Bag} of $X$ is a function $b\colon X\to\NN_{0}$
of finite support. We interpret this as a multi-index.

We define the \define{Empty Bag} of $X$ to be the constant function
$e\colon X\to\ZZ$ such that $e(x)=0$ for all $x\in X$.

Furthermore, we may define the set $\Bags(X)$ to be the set of all bag
of $X$.
\end{definition}

\begin{remark}[Integer-valued bags]
We could generalize the notion of a bag to functions $b\colon X\to\ZZ$
provided they have finite support. This allows us to discuss formal
Laurent series and formal Laurent polynomials (and, for Vertex
Operator Algebraists, formal distributions). But for formal power
series and formal polynomials, we need bags to be non-negative valued.
\end{remark}

\begin{definition}[Partial order of bags]\mml{pre_poly:def 14}
Let $X$ be an ordered set.
Let $p$ and $q$ be bags of $X$.
\begin{enumerate}
\item We have $p < q$ whenever there exists a $k$ such that
$p(X_{k})<q(X_{k})$ and for all $l<k$ we have $p(X_{l})=q(X_{l})$.
\item We have $p\leq q$ whenever $p<q$ or $p=q$.
\item We say $p$ \define{Divides} $q$ if for each $X_{k}\in X$ we have
  $p(X_{k})\leq q(X_{k})$.
\end{enumerate}
\end{definition}

\begin{definition}[Divisors of a bag]\mml{pre_poly:def 16}
Let $X$ be an ordered set, let $b$ be a bag of $X$. We want to define
a notion of ``divisors of $b$'', but it requires first introducing a
provisional notion of an ``initial segment of bags''.

Let $B$ be a non empty finite subset of $\Bags(X)$.
We want to define the \define{Initial Segment} of bags of $B$ to be
the finite sequence $S$ of bags of $X$ such that $\rng(S)=B$ and also
for all natural numbers $m$ and $n$ with $m < n$ we have the bags $S_{m}<S_{n}$.

We define the \define{Divisors} of $b$ to be the finite sequence of
$\Bags(X)$ satisfying
there exists a non empty finite subset $D$ of $\Bags(X)$ such that
the set of divisors equals the initial segment of bags of $S$ and for
$p$ being a bag of $X$ we have $p\in S$ if and only if $p$ divides $b$.
So the divisors of $b$ is the finite sequence of all possible bags
which divides $b$.
\end{definition}

\begin{definition}[Decomposition of a bag]\mml{pre_poly:def 17}
Let $X$ be an ordered set, let $b$ be a bag of $X$.
We define the \define{Decomposition} of $b$ to be the finite sequence $d$
of ordered pairs on $\Bags(X)$ such that
$\dom(d)=\dom({\rm divisors}(b))$ and
for each natural number $i\in\dom({\rm decomp}(b))$ and for each bag
$p$ of $X$ such that $p=({\rm divisors}(b))_{i}$ we have
${\rm decomp}(b)_{i} = (p, b \monus p)$.

Again, when viewed as monomials, this gives us the possible
factorization of a monomial as the product of two monomials. This is
necessary to define the Cauchy product of series and polynomials.
\end{definition}

\begin{definition}[Formal power series and formal polynomial]\mml{polynom1}
Let $X = \{X_{1},\dots,X_{n}\}$ be $n$ unknowns.
Let $R$ be a 1-sorted structure.
We define a \define{Formal Power Series} with coefficients in $R$ and unknowns
in $X$ to be a function $f\colon\Bags(X)\to R$. This is usually
written as
\begin{equation}
f(X_{1},\dots,X_{n}) = \sum_{b\,\in\Bags(X)}f(b)X^{b}
\end{equation}
where $X^{b} = X_{1}^{b_{1}}X_{2}^{b_{2}}(\cdots)X_{n}^{b_{n}}$ where
we abuse notation abbreviating $b_{i}=b_{X_{i}}$.

We then define a \define{Formal Polynomial} with coefficients in $R$
and unknowns in $X$ to be a formal power series with finite support.
\end{definition}

\begin{definition}[Addition of formal power series]\mml{polynom1:def 6}
Let $X$ be a set of unknowns, let $L$ be a nonempty additive magma.
Let $p$ and $q$ be formal power series with coefficients in $L$ and
unknowns in $X$.
We define the \define{Sum} of $p$ and $q$ to be the formal power
series $p+q$ (with coefficients in $L$ and unknowns in $X$) is such
that % $\dom(p+q)=\dom(p)\cap\dom(q)$ and
for $\alpha\in\dom(p+q)$ we
have $(p+q)_{\alpha} = p_{\alpha} + q_{\alpha}$.

This notion extends to the sum of formal polynomials.
\end{definition}

\begin{definition}[Negation and subtraction of formal power series]
Let $X$ be a set of unknowns, let $L$ be a nonempty additive magma.
Let $p$ be a formal power series with coefficients in $L$ and
unknowns in $X$.

We define the \define{Negation} of $p$ to be the formal power series $-p$ such that for each bag
$b\in\dom(p)$ we have $(-p)_{b}=-(p_{b})$ (i.e., the coefficients are
all negated).

Let $q$ be another formal power series in unknowns $X$ and
coefficients in $R$.
We define the \define{Subtraction} of $p$ with $q$ to be the formal
power series $p - q$ equal to $p + (-q)$.
\end{definition}

\begin{definition}[Product of formal power series]\mml{polynom1:def 10}
Let $X$ be a set of unknowns, let $L$ be a double loop which is an
additive group, let $p$ and $q$ be formal power series
of $X$.

We define the \define{(Cauchy) Product} of $p$ with $q$ to be the
formal power series $pq$ in unknowns $X$ and coefficients $L$ such
that for $b$ being a bag of $X$ and $s$ being a finite sequence of $L$
such that $(pq)_{b}=\sum s$ and $|s|=|{\rm decomp}(b)|$ and for $k$
being a natural number such that $k\in\dom(s)$ there exists bags
$b_{1}$ and $b_{2}$ of $X$ such that
$({\rm decomp}(b))_{k}=(b_{1},b_{2})$ and $s_{k}=p_{b_{1}}q_{b_{2}}$.

Observe this extends to formal polynomials in the obvious way.
\end{definition}

\begin{theorem}[Distributivity of Cauchy product over addition]\mml{polynom1:26}
Let $X$ be a set of unknowns, let $R$ be a ring. Let $p$, $q$, $r$ be
formal power series in unknowns $X$ and coefficients in $R$. Then
$p(q+r)=(pq) + (pr)$.
\end{theorem}

\begin{theorem}[Associativity of Cauchy product]\mml{polynom1:27}
Let $X$ be a set of unknowns, let $R$ be a ring. Let $p$, $q$, $r$ be
formal power series in unknowns $X$ and coefficients in $R$. Then
$(pq)r=p(qr)$.
\end{theorem}

\begin{theorem}[Unit and absorption laws for Cauchy product]\mml{polynom1:28,29}
Let $X$ be a set of unknowns, let $R$ be a ring. Let $p$ be a
formal power series in unknowns $X$ and coefficients in $R$. 
\begin{enumerate}
\item If $0$ is the formal power series with zeroes for all its
  coefficients, then $p0=0$
\item If $1$ is the formal power series with zeroes for all its
  nonconstant coefficients and $1_{R}$ for its constant coefficient,
  then $1p=p$ and $p1=p$.
\end{enumerate}
\end{theorem}

\section{Ideals}

\begin{definition}[Ideals of a ring]\mml{ideal_1}
Let $R$ be a ring. Let $J$ be a subset of $R$.

We call $J$ a \define{Left ideal} of $R$ if
\begin{itemize}
\property{Contains zero} $0\in J$ and
\property{Closed under addition} for any $x\in J$ and $y\in J$ we have
  $x+y\in J$
\property{Closed under left multiplication} $RJ\subset J$ (when we multiply any
element $j\in J$ on the left by an element $r\in R$ we obtain $rj\in J$).
\end{itemize}

%\medbreak%
\noindent%
We call $J$ a \define{Right ideal} of $R$ if
\begin{itemize}
\property{Contains zero} $0\in J$ and
\property{Closed under addition} for any $x\in J$ and $y\in J$ we have
  $x+y\in J$
\property{Closed under right multiplication} $JR\subset J$ (when we
  multiply any element $j\in J$ on the right by an element $r\in R$ we obtain $jr\in J$).
\end{itemize}

%\medbreak%
\noindent%
We call $J$ a \define{Two-sided ideal} (or simply an \emph{Ideal}) of
$R$ if it is both a right ideal of $R$ and a left ideal of $R$.
In this case, we write $J\ideal R$. When $J\neq R$, we write
$J\properideal R$.
\end{definition}

\begin{theorem}[Left ideals are right ideals over commutative rings]
Let $R$ be a commutative ring.
\begin{enumerate}
\item Every left ideal $J$ of $R$ is also a right ideal of $R$.
\item Every right ideal $J$ of $R$ is also a left ideal of $R$.
\end{enumerate}
Therefore, we will just speak of \define{Ideals} of a commutative ring.
\end{theorem}
(This is a fact registered in \texttt{ideal\_1}.)

\begin{theorem}[Kernels of ring morphisms are ideals]\mml{ring_2}
Let $R$ be a nonempty double loop structure.
Let $S$ be a ring. Let $f\colon R\to S$ be a ring morphism.
Then $\ker(f)$ is an ideal of $R$.
\end{theorem}

\begin{theorem}[(Krull) Every nonzero ring has a maximal ideal]\mml{ring_1}
Let $R$ be a nondegenerate Ring.
There exists a maximal ideal of $R$.
\end{theorem}

(This is a registered fact in \texttt{RING\_1}.)

\begin{proof}[Proof sketch]
We consider the relation $\{(I,J)\mid I\properideal R, J\properideal R, I\subset J\}$.
We see this is nonempty.
There exists at least one chain to this relation.
Then we use Zorn's lemma to find the maximal element of the chain.
We see that it must be a maximal proper ideal of $R$.
\end{proof}

\begin{definition}[Prime and quasi-prime subsets]\mml{ring_1:def 1,2}
Let $R$ be a nonempty multiplicative loop structure.
Let $S\subset R$ be a subset.
We call $S$ \define{Quasi-Prime} to mean: for any elements $a$ and $b$
of $R$, if $ab\in S$, then either $a\in S$ or $b\in S$.

If further $S\neq R$ is a proper subset, then we call $S$ \define{Prime}.
\end{definition}

\begin{definition}[Quotient ring]\mml{ring_1:def 6}
Let $R$ be a nonempty (possibly degenerate) Ring.
Let $I$ be an ideal of $R$.
We define the \define{Quotient Ring} of $R$ by $I$ to be the strict
Ring $R/I$ whose underlying set consists equivalence classes of the form
$x + I$ for each $x\in R$, addition is defined by $(a+I)+(b+I)=(a+b)+I$,
multiplication is defined by $(a+I)(b+I)=ab+I$, the zero of it is $0_{R/I}=0+I$,
and the one of it is $1_{R/I}=1_{R}+I$.
\end{definition}

\begin{theorem}[Quotient of commutative ring by maximal ideal is skew-field]\mml{ring_1:21}
Let $R$ be a non-degenerate commutative unital ring.
Let $\mathfrak{m}\properideal R$ be a proper ideal of $R$. 
Then $\mathfrak{m}$ is a maximal ideal if and only if the quotient ring $R/\mathfrak{m}$ is 
a skew-field.
\end{theorem}

\begin{definition}[Canonical morphism from ring to quotient ring]\mml{ring_2:def 5}
Let $R$ be a ring. Let $I\ideal R$ be an ideal.
We define the \define{Canonical Morphism} of $I$ to be the surjective
ring morphism $f\colon R\to R/I$ sending $x\in R$ to $x+I$.
\end{definition}

\begin{theorem}[Quotient ring $R/I$ is $R$-homomorphic]\mml{ring_2}
Let $R$ be a ring. Let $I\ideal R$.
We claim the quotient ring $R/I$ is $R$-homomorphic.
\end{theorem}

\begin{proof}
Take the canonical morphism. Hence the result.
\end{proof}

\begin{definition}[Ideal generated by a set]\mml{ideal_1:def 14}
Let $R$ be a nonempty double loop structure, let $S\subset R$ be some subset of $R$.
We define the \define{(Two-Sided) Ideal Generated by} $S$ to be the
Ideal $\langle S\rangle$ of $R$ such that
\begin{itemize}
\property{It contains $S$} $S\subset\langle S\rangle$, and
\property{Smallest ideal containing $S$} For any ideal $I\ideal R$
such that $S\subset I$, we have $\langle S\rangle\subset I$.
\end{itemize}
(We can similarly define ``the left-ideal generated by $S$''
[\texttt{IDEAL\_1:def 15}] and ``the right-ideal generated by $S$''
[\texttt{IDEAL\_1:def 16}] by replacing ``ideal'' with ``left-ideal''
or ``right-ideal'' in the definition.)
\end{definition}

\begin{theorem}[Ideals generate themselves]\mml{ideal_1:44}
Let $R$ be a nonempty double loop structure.
Let $I\ideal R$ be an ideal of $R$.
Then $\langle I\rangle=I$.
\end{theorem}

\begin{theorem}[Subsets generate subideals]\mml{ideal_1:57}
Let $R$ be a nonempty double loop structure.
Let $A$ and $B$ be subsets of $R$.
If $A\subset B$, then the ideals they generate $\langle A\rangle\subset\langle B\rangle$.
\end{theorem}

\begin{theorem}[Elements of an ideal generate subideals]\mml{ring_2:4}
Let $R$ be a commutative ring.
Let $I\ideal R$ be an ideal.
For any $x\in I$, we see $\langle x\rangle\subset I$.
\end{theorem}

\begin{definition}[Multiplying a subset by an element]\mml{ideal_1:def 18}
Let $M$ be a nonempty multiplicative magma.
Let $I\subset M$ be a subset of $M$.
Let $a\in M$ be an element of $M$.
We define the term $aI$ to be the subset of $M$ equal to $\{ai\in M\mid i\in I\}$.
\end{definition}

\begin{definition}[Adding two subsets together]\mml{ideal_1:def 19}
Let $A$ be an additive magma.
Let $I$ and $J$ be subsets of $A$.
We define the term $I+J$ to be the subset of $A$ equal to
$I+J:=\{(i+j)\in A\mid i\in I, j\in J\}$.
\end{definition}

\begin{definition}[Principal ideal]\mml{ideal_1:def 27}
Let $R$ be a nonempty double loop structure.
Let $I$ be an ideal of $R$.
We say $I$ is \define{Principal} if there exists an element $x$ of $R$
such that it generates $I = \langle x\rangle$.
\end{definition}

\begin{definition}[Principal ideal domains]\mml{ring_2}
We define [the soft type of] a \define{Principal Ideal Domain} to be
an integral domain $R$ such that
\begin{itemize}
\property{Ideals are principal}\mml{ideal_1:def 28} Every ideal
$I\ideal R$ is principal, i.e., generated by a single element $x\in R$
such that $I=\langle x\rangle$.
\end{itemize}
\end{definition}

\begin{definition}[Radical of a subset of a double loop]\mml{ideal_1:def 24}
Let $R$ be a nonempty well-unital double loop structure.
Let $I$ be a subset of $R$.
We define the \define{Radical} of $I$ to be the subset $\Radical{I}$
of $R$ equal to $\Radical{I}:=\{a\in R\mid\exists n\in\NN\ldotp a^{n}\in I\}$.
\end{definition}

\begin{theorem}[Radical of an ideal is an ideal]\mml{ideal_1}
Let $R$ be a well-unital associative commutative nonempty double loop structure.
Let $I$ be an ideal of $R$.
Then $\Radical{I}$ is an ideal of $R$.
\end{theorem}

(This is a registered fact in \texttt{ideal\_1}.)

\begin{definition}[Finitely-generated ideal]\mml{ideal_1:def 25}
Let $R$ be a nonempty double loop structure.
Let $I$ be an ideal of $R$.
We say $I$ is \define{Finitely-Generated} if there exists a finite
subset $G\subset R$ such that it generates $I=\langle G\rangle$.
\end{definition}

\begin{definition}[Noetherian double loops]\mml{ideal_1:def 26}
Let $R$ be a nonempty double loop structure.
We say $R$ is \define{Noetherian} if every ideal of $R$ is finitely-generated.
\end{definition}

\begin{theorem}[Principal ideal domains are Noetherian]\mml{ideal_1:95}
For any $R$ being a principal ideal domain,
we see that $R$ is Noetherian.
\end{theorem}

\begin{proof}[Proof sketch]
Let $R$ be a principal ideal domain. We want to show every ideal
$I\ideal R$ is finitely-generated. But every ideal $I$ is principal,
so it is generated by a singleton set. Singleton sets are finite sets.
Therefore every ideal is generated by a finite set. Hence every ideal
of $R$ is finitely-generated. (Hence $R$ is Noetherian.)
\end{proof}